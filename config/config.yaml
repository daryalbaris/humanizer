# AI Humanizer System Configuration
# Version: 1.0
# Date: 2025-10-30

humanizer:
  # Maximum iterations for humanization process
  max_iterations: 7

  # Detection threshold (15% = proxy target for human-like)
  detection_threshold: 0.15

  # Early termination if improvement less than 2% between iterations
  early_termination_improvement: 0.02

# Aggression levels for humanization intensity
aggression_levels:
  gentle: 1
  moderate: 2
  aggressive: 3
  intensive: 4
  nuclear: 5

# Translation chain for diversity enhancement
translation_chain:
  enabled: true
  # Activate if <5% improvement after 3 iterations
  trigger_threshold: 0.05
  # Target languages: German, Japanese (high linguistic diversity)
  languages: ["de", "ja"]

# File paths
paths:
  glossary: "data/glossary.json"
  patterns: "data/patterns.json"
  checkpoint_dir: ".humanizer/checkpoints"
  log_dir: ".humanizer/logs"
  output_dir: ".humanizer/output"

# Performance settings
performance:
  max_memory_gb: 3
  # Set to true if GPU available (significantly speeds up BERTScore)
  enable_gpu: false

# Logging configuration
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "json"  # json or text

  # Log rotation settings
  rotation:
    max_bytes: 10485760  # 10 MB
    backup_count: 5

# Component-specific settings
components:
  term_protector:
    # auto, tier1, tier2, tier3
    default_protection_tier: "auto"

  paraphraser:
    # gentle, moderate, aggressive, intensive, nuclear
    default_aggression: "moderate"

  burstiness_enhancer:
    # Target burstiness score (0-1, higher = more varied)
    target_burstiness: 0.7

  fingerprint_remover:
    # Minimum confidence for fingerprint detection (0-1)
    detection_confidence: 0.75

  perplexity_calculator:
    # GPT-2 model variant: gpt2, gpt2-medium, gpt2-large
    model: "gpt2"

  validator:
    # BERTScore model: microsoft/deberta-xlarge-mnli (accurate) or roberta-large (faster)
    bertscore_model: "roberta-large"
    # Minimum acceptable semantic similarity (0-1)
    min_semantic_similarity: 0.85
    # Minimum acceptable BLEU score (0-1)
    min_bleu_score: 0.70

# Checkpoint settings
checkpoints:
  # Save checkpoint after each iteration
  auto_save: true
  # Compress checkpoints (saves disk space)
  compress: true
  # Maximum checkpoints to keep (0 = unlimited)
  max_keep: 10

# Experimental features (use with caution)
experimental:
  # Enable parallel processing of components (may use more memory)
  parallel_processing: false
  # Cache intermediate results for faster re-runs
  caching: true
